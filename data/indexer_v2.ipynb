{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Mapping, Any\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, LangchainEmbedding, ServiceContext, PromptHelper\n",
    "from llama_index.logger import LlamaLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./datasets/huggingface_docs/').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    model_name: str = 't5-small'\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        outputs = self.model.generate(input_ids)\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"name_of_model\": self.model_name}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return self.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CustomLLM()\n",
    "llm('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hkunlp/instructor-large\"\n",
    "embed_instruction = \"Represent the Hugging Face library documentation\"\n",
    "query_instruction = \"Query the most relevant piece of information from the Hugging Face documentation\"\n",
    "\n",
    "# embedding_model = HuggingFaceEmbeddings()\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name=model_name,\n",
    "    embed_instruction=embed_instruction,\n",
    "    query_instruction=query_instruction\n",
    ")\n",
    "\n",
    "max_input_size = 4096\n",
    "num_output = 256\n",
    "max_chunk_overlap = 20\n",
    "service_context = ServiceContext(\n",
    "    llm_predictor=LLMPredictor(llm=CustomLLM()),\n",
    "    embed_model=LangchainEmbedding(embedding_model),\n",
    "    prompt_helper=PromptHelper(max_input_size, num_output, max_chunk_overlap),\n",
    "    node_parser=SimpleNodeParser(),\n",
    "    llama_logger=LlamaLogger()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
    "index.save_to_disk('index_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.query('how to create pipeline object?')#.response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_qa_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
